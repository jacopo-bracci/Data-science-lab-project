{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# import torchaudio.transforms\n",
    "import librosa\n",
    "import librosa.display\n",
    "from skimage.util.shape import view_as_windows\n",
    "from skimage.util.shape import view_as_blocks\n",
    "import math\n",
    "import joblib\n",
    "from numpy import save, load\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from IPython.lib.display import Audio\n",
    "\n",
    "def plot_waveform(waveform, sample_rate, title):\n",
    "    num_frames = waveform.shape[0]\n",
    "    num_channels = 1\n",
    "    time_axis = torch.arange(0, num_frames) / sample_rate\n",
    "\n",
    "    figure, axes = plt.subplots(num_channels, 1)\n",
    "    if num_channels == 1:\n",
    "        axes = [axes]\n",
    "    for c in range(num_channels):\n",
    "        axes[c].plot(time_axis, waveform, linewidth=1)\n",
    "        axes[c].grid(True)\n",
    "        if num_channels > 1:\n",
    "            axes[c].set_ylabel(f'Channel {c+1}')\n",
    "    figure.suptitle(title)\n",
    "    plt.show(block=False)\n",
    "    print(\"\")\n",
    "\n",
    "def play_audio(data, sample_rate):\n",
    "    display(Audio(data, rate=sample_rate, normalize=False))\n",
    "\n",
    "def plot_spectrogram(spectrogram, sr=16000, n_fft=512):\n",
    "    librosa.display.specshow(data=spectrogram, sr=sr, n_fft=n_fft, x_axis='time', y_axis='mel')\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# CONSTANT definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PRE_EMPHASIS = 0.95\n",
    "TRIM_TOP_DB = 21\n",
    "N_FTT = 256\n",
    "N_MFCC = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_df = pd.read_csv(\"dsl_data\\\\development.csv\", header=0)\n",
    "test_dev_df = dev_df[:].copy()\n",
    "\n",
    "# test_dev_df = dev_df.iloc[randomlist].copy()\n",
    "# test_dev_df = test_dev_df.reset_index().drop(columns=[\"index\"])\n",
    "\n",
    "spectrum_list = []"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization(data):\n",
    "    # data_norm = (data-data.mean())/data.std()\n",
    "\n",
    "    data_norm = (data-data.min())/(data.max()-data.min())\n",
    "\n",
    "    return data_norm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "silence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_silence(data, trim_top_db_par=55):\n",
    "    energy = data**2\n",
    "\n",
    "    # FRONT TRIMMING\n",
    "    cumulative_energy = np.cumsum(energy)\n",
    "    _, index = librosa.effects.trim(y=cumulative_energy, top_db=trim_top_db_par)\n",
    "    front_index = index[0]\n",
    "\n",
    "    # BACK TRIMMING\n",
    "    cumulative_energy_reversed = np.abs(cumulative_energy-np.sum(energy))\n",
    "    _, index = librosa.effects.trim(y=cumulative_energy_reversed, top_db=trim_top_db_par+15)\n",
    "    back_index = index[1]\n",
    "\n",
    "    # # Plotting POST trimming\n",
    "    # plot_waveform(audio_data[front_index:back_index], sr, f\"signal AFTER OVERALL trimming\")\n",
    "    # play_audio(audio_data[front_index:back_index], sr)\n",
    "\n",
    "    # Append sample rate\n",
    "    return data[front_index:back_index]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mel_spectrogram_grid_search_PARALLEL(int_quale_silenzio, develop_eval_df, list_of_attributes):\n",
    "    if \"action\" in list_of_attributes:\n",
    "        outliers_removal = True\n",
    "    else:\n",
    "        outliers_removal = False\n",
    "    series_with_mel_spec_list = Parallel(n_jobs=-1, prefer=\"processes\")(\n",
    "        delayed(single_mel_spec_grid_meow)(series, int_quale_silenzio, outliers_removal)\n",
    "        for _, series in develop_eval_df[list_of_attributes].iterrows())\n",
    "\n",
    "    print(\"mel spec series list is done!\")\n",
    "    return series_with_mel_spec_list\n",
    "\n",
    "\n",
    "def single_mel_spec_grid_meow(series, int_quale_silenzio, outliers_removal):\n",
    "    wav_path = series[\"path\"]\n",
    "    # READING wav file\n",
    "    data, sample_frequency = librosa.load(wav_path, sr=None)\n",
    "\n",
    "    # removing silence\n",
    "    data, _ = librosa.effects.trim(data, top_db=TRIM_TOP_DB)\n",
    "\n",
    "    # OUTLIERS removal\n",
    "    if outliers_removal:\n",
    "        length = data.shape[0]/sample_frequency\n",
    "        if length > 4 or length < 0.3:\n",
    "            # return None, None\n",
    "            return pd.concat([series, pd.Series({\"spectrogram\": None})]), pd.concat([series, pd.Series({\"spectrogram\": None})])\n",
    "\n",
    "    # pre emphasis\n",
    "    data = librosa.effects.preemphasis(y=data, coef=PRE_EMPHASIS)\n",
    "\n",
    "    # DATA normalization\n",
    "    data = normalization(data)\n",
    "\n",
    "    # Short Term Fourier Transform\n",
    "    sgram = librosa.stft(data,\n",
    "                         n_fft=N_FTT,\n",
    "                         win_length=N_FTT,\n",
    "                         hop_length=N_FTT//4)\n",
    "    # Taking MAGNITUDE of stft\n",
    "    sgram_mag, _ = librosa.magphase(sgram)\n",
    "    # MEL spectrogram of magnitude\n",
    "    mel_scale_sgram = librosa.feature.melspectrogram(S=sgram_mag,\n",
    "                                                     sr=sample_frequency,\n",
    "                                                     n_mels = 128)\n",
    "    # ADJUSTING SCALE to dB\n",
    "    mel_sgram = librosa.power_to_db(mel_scale_sgram, ref=np.min)\n",
    "\n",
    "    mel_sgram = (mel_sgram-np.mean(mel_sgram, axis=(0, 1)))/np.std(mel_sgram, axis=(0, 1))\n",
    "    # mel_sgram = (mel_sgram-np.min(mel_sgram, axis=(0, 1)))/(np.min(mel_sgram, axis=(0, 1)) - np.max(mel_sgram, axis=(0, 1)))\n",
    "\n",
    "\n",
    "    # Data AUGMENTATION\n",
    "    DATA_AUG = False\n",
    "    if outliers_removal and DATA_AUG:\n",
    "        gender = series[\"gender\"]\n",
    "        if gender == \"female\":\n",
    "            n_steps = -1.2\n",
    "        else:\n",
    "            n_steps = 1.2\n",
    "        augmented_data = librosa.effects.pitch_shift(y=data,\n",
    "                                                    sr=sample_frequency,\n",
    "                                                    n_steps=n_steps)\n",
    "        # same for AUGMENTED DATA\n",
    "        sgram_aug = librosa.stft(augmented_data,\n",
    "                             n_fft=N_FTT,\n",
    "                             win_length=N_FTT,\n",
    "                             hop_length=N_FTT//4)\n",
    "        # Taking MAGNITUDE of stft\n",
    "        sgram_mag_aug, _ = librosa.magphase(sgram_aug)\n",
    "        # MEL spectrogram of magnitude\n",
    "        mel_scale_sgram_aug = librosa.feature.melspectrogram(S=sgram_mag_aug,\n",
    "                                                         sr=sample_frequency,\n",
    "                                                         n_mels = 128)\n",
    "        # ADJUSTING SCALE to dB\n",
    "        mel_sgram_aug = librosa.power_to_db(mel_scale_sgram_aug, ref=np.min)\n",
    "    else:\n",
    "        mel_sgram_aug = None\n",
    "\n",
    "    # # PLOTTING spectrogram\n",
    "    # plot_spectrogram(mel_sgram, sample_frequency)\n",
    "\n",
    "    return pd.concat([series, pd.Series({\"spectrogram\": mel_sgram})]), pd.concat([series, pd.Series({\"spectrogram\": mel_sgram_aug})])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mfcc_spectrogram_grid_search_PARALLEL(int_quale_silenzio, develop_eval_df, list_of_attributes):\n",
    "    if \"action\" in list_of_attributes:\n",
    "        outliers_removal = True\n",
    "    else:\n",
    "        outliers_removal = False\n",
    "    series_with_mel_spec_list = Parallel(n_jobs=-1, prefer=\"processes\")(\n",
    "        delayed(single_mfcc_spec_grid_meow)(series, int_quale_silenzio, outliers_removal)\n",
    "        for _, series in develop_eval_df[list_of_attributes].iterrows())\n",
    "\n",
    "    print(\"mel spec series list is done!\")\n",
    "    return series_with_mel_spec_list\n",
    "\n",
    "\n",
    "def single_mfcc_spec_grid_meow(series, int_quale_silenzio, outliers_removal):\n",
    "    wav_path = series[\"path\"]\n",
    "    # READING wav file\n",
    "    data, sample_frequency = librosa.load(wav_path, sr=None)\n",
    "\n",
    "    # removing silence\n",
    "    data, _ = librosa.effects.trim(data, top_db=TRIM_TOP_DB)\n",
    "\n",
    "    # OUTLIERS removal\n",
    "    if outliers_removal:\n",
    "        length = data.shape[0]/sample_frequency\n",
    "        if length > 4 or length < 0.3:\n",
    "            # return None, None\n",
    "            return pd.concat([series, pd.Series({\"spectrogram\": None})]), pd.concat([series, pd.Series({\"spectrogram\": None})])\n",
    "\n",
    "    # pre emphasis\n",
    "    data = librosa.effects.preemphasis(y=data, coef=PRE_EMPHASIS)\n",
    "\n",
    "    # DATA normalization\n",
    "    data = normalization(data)\n",
    "\n",
    "    # Short Term Fourier Transform\n",
    "    sgram = librosa.stft(data,\n",
    "                         n_fft=N_FTT,\n",
    "                         win_length=N_FTT,\n",
    "                         hop_length=N_FTT//4)\n",
    "    # Taking MAGNITUDE of stft\n",
    "    sgram_mag, _ = librosa.magphase(sgram)\n",
    "    # MEL spectrogram of magnitude\n",
    "    mel_scale_sgram = librosa.feature.melspectrogram(S=sgram_mag,\n",
    "                                                     sr=sample_frequency,\n",
    "                                                     n_mels = 128)\n",
    "    # ADJUSTING SCALE to dB\n",
    "    mel_sgram = librosa.power_to_db(mel_scale_sgram, ref=np.min)\n",
    "\n",
    "\n",
    "    mfcc = librosa.feature.mfcc(y=data, sr=sample_frequency, S=mel_sgram, n_mfcc=40)\n",
    "\n",
    "    # Data AUGMENTATION\n",
    "    DATA_AUG = False\n",
    "    if outliers_removal and DATA_AUG:\n",
    "        gender = series[\"gender\"]\n",
    "        if gender == \"female\":\n",
    "            n_steps = -1.2\n",
    "        else:\n",
    "            n_steps = 1.2\n",
    "        augmented_data = librosa.effects.pitch_shift(y=data,\n",
    "                                                    sr=sample_frequency,\n",
    "                                                    n_steps=n_steps)\n",
    "        # same for AUGMENTED DATA\n",
    "        sgram_aug = librosa.stft(augmented_data,\n",
    "                             n_fft=N_FTT,\n",
    "                             win_length=N_FTT,\n",
    "                             hop_length=N_FTT//4)\n",
    "        # Taking MAGNITUDE of stft\n",
    "        sgram_mag_aug, _ = librosa.magphase(sgram_aug)\n",
    "        # MEL spectrogram of magnitude\n",
    "        mel_scale_sgram_aug = librosa.feature.melspectrogram(S=sgram_mag_aug,\n",
    "                                                         sr=sample_frequency,\n",
    "                                                         n_mels = 128)\n",
    "        # ADJUSTING SCALE to dB\n",
    "        mel_sgram_aug = librosa.power_to_db(mel_scale_sgram_aug, ref=np.min)\n",
    "    else:\n",
    "        mel_sgram_aug = None\n",
    "\n",
    "    # # PLOTTING spectrogram\n",
    "    # plot_spectrogram(mel_sgram, sample_frequency)\n",
    "\n",
    "    return pd.concat([series, pd.Series({\"spectrogram\": mel_sgram})]), pd.concat([series, pd.Series({\"spectrogram\": mfcc})])\n",
    "\n",
    "    # return pd.concat([series, pd.Series({\"spectrogram\": mel_sgram})]), pd.concat([series, pd.Series({\"spectrogram\": mel_sgram_aug})])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "characterize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def characterize_spectrum(spectrum_list, n_time, n_freq):\n",
    "    characterize = []\n",
    "    for spectrum in spectrum_list:\n",
    "        f, t = spectrum.shape\n",
    "        magic_time = t // n_time\n",
    "        magic_freq = n_freq\n",
    "\n",
    "        # BLOCKS of fixed size\n",
    "        # B_w = view_as_windows(spectrum[:, :t-t%n_time], window_shape=(magic_freq, magic_time), step=(n_freq, magic_time//2))\n",
    "        B_w = view_as_blocks(spectrum[:, :t - t % n_time], block_shape=(magic_freq, magic_time))\n",
    "\n",
    "        # RESHAPING\n",
    "        B_w = B_w.reshape(B_w.shape[0]*B_w.shape[1], B_w.shape[2]*B_w.shape[3])\n",
    "\n",
    "        # CONCATENATING mean and std\n",
    "        B_characterized = np.concatenate([B_w.mean(axis=1), B_w.std(axis=1)])\n",
    "\n",
    "\n",
    "        characterize.append(np.concatenate([B_characterized] ))\n",
    "\n",
    "    return np.array(characterize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def characterize_spectrum_PARALLEL(series_with_mel_spec_list, n_time, n_freq):\n",
    "    characterized_list_of_series = Parallel(n_jobs=-1, prefer=\"processes\")(\n",
    "        delayed(char_spec_Single_BLOCK_view)(series, n_time, n_freq)\n",
    "        for series in series_with_mel_spec_list)\n",
    "    return pd.DataFrame(characterized_list_of_series)\n",
    "\n",
    "def char_spec_Single_BLOCK_view(series, n_time, n_freq):\n",
    "    spectrum = series[\"spectrogram\"]\n",
    "    f, t = spectrum.shape\n",
    "    magic_time = t // n_time\n",
    "    magic_freq = n_freq\n",
    "\n",
    "    # BLOCKS of fixed size\n",
    "    B_w = view_as_blocks(spectrum[:, :t - t % n_time], block_shape=(magic_freq, magic_time))\n",
    "\n",
    "    # RESHAPING\n",
    "    B_w = B_w.reshape(B_w.shape[0] * B_w.shape[1], B_w.shape[2], B_w.shape[3])\n",
    "\n",
    "    # CONCATENATING mean and std\n",
    "    # B_characterized = np.concatenate([B_w.mean(axis=(1, 2)), B_w.std(axis=(1, 2))])\n",
    "    B_characterized = np.concatenate([B_w.mean(axis=(1, 2))])\n",
    "\n",
    "    \n",
    "    series.drop(labels=[\"spectrogram\"], inplace=True)\n",
    "\n",
    "    return pd.concat([series, pd.Series(B_characterized)])\n",
    "\n",
    "def char_spec_Single_WINDOW_view(series, n_time, n_freq):\n",
    "    spectrum = series[\"spectrogram\"]\n",
    "    f, t = spectrum.shape\n",
    "    f_size = n_freq\n",
    "\n",
    "    t_size = math.ceil(t/n_time)\n",
    "    while (t_size*n_time - t) % (n_time-1) != 0:\n",
    "        t_size += 1\n",
    "    minus_step_time = int((t_size*n_time - t) / (n_time-1))\n",
    "    minus_step_freq = 0\n",
    "\n",
    "    window_view = view_as_windows(spectrum, window_shape=(f_size, t_size), step=(f_size-minus_step_freq, t_size-minus_step_time))\n",
    "\n",
    "    # RESHAPING\n",
    "    window_view = window_view.reshape(window_view.shape[0]*window_view.shape[1], window_view.shape[2], window_view.shape[3])\n",
    "\n",
    "    # Calculating various statistic measures on the spectrum.\n",
    "    mean = np.mean(window_view, axis=(1, 2))\n",
    "    # std = np.std(window_view, axis=(1,2))\n",
    "    # median= np.median(window_view,axis=1)\n",
    "    # skew = stats.skew(window_view, axis=1)\n",
    "    # kurt = stats.kurtosis(window_view, axis=1)\n",
    "    # maximum = np.amax(window_view, axis=1)\n",
    "    # minimum = np.amin(window_view, axis=1)\n",
    "\n",
    "    # Concatinating all the statistic measures and adding to the feature list.\n",
    "    # addList = np.concatenate((mean,median,std,skew,kurt,maximum,minimum))\n",
    "    # addList = np.concatenate((mean,median,std,skew,kurt))\n",
    "    # addList = np.concatenate((mean,median,std))\n",
    "    addList = mean\n",
    "\n",
    "    return pd.concat([series, pd.Series(addList)])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "boilerplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rinomina colonne final spectra (colonne della Mean e Std)\n",
    "def rename_columns(final_spectra_arr, test_dev_df_copy):\n",
    "    size_of_chacterized_spectra = final_spectra_arr[0].shape[0]\n",
    "    str_list = [str(x) for x in range(size_of_chacterized_spectra)]\n",
    "    test_dev_df_copy = pd.concat([test_dev_df_copy, pd.DataFrame(final_spectra_arr, columns=str_list)], axis=1)\n",
    "    return test_dev_df_copy\n",
    "\n",
    "def rename_columns_PARALLEL(CHAR_SPEC_dataframe):\n",
    "    new_col_names = []\n",
    "    for col in CHAR_SPEC_dataframe.columns:\n",
    "        if isinstance(col, int):\n",
    "            new_col_names.append(str(col))\n",
    "        else:\n",
    "            new_col_names.append(col)\n",
    "    CHAR_SPEC_dataframe.columns = new_col_names\n",
    "    return CHAR_SPEC_dataframe\n",
    "\n",
    "\n",
    "# Divide Numerical e Categorical attribute\n",
    "def num_cat_attributes(test_dev_df):\n",
    "    lista_colonne = list(test_dev_df.columns)\n",
    "    zero_index = lista_colonne.index('0')\n",
    "\n",
    "    # WITHOUT LANGUAGES 'Self-reported fluency level ', 'First Language spoken', 'Current language used for work/school',\n",
    "    categorical_attributes = ['gender', 'ageRange']\n",
    "    numerical_attributes = lista_colonne[zero_index:]\n",
    "\n",
    "    return numerical_attributes, categorical_attributes\n",
    "\n",
    "\n",
    "# PIPELINE definition\n",
    "def pipeline_definition(numerical_attributes, categorical_attributes, model):\n",
    "    numeric_transformer = Pipeline(\n",
    "        steps=[(\"imputer\", SimpleImputer(strategy=\"median\"))]\n",
    "    )\n",
    "\n",
    "    categorical_transformer = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", numeric_transformer, numerical_attributes),\n",
    "            (\"cat\", categorical_transformer, categorical_attributes),\n",
    "        ]\n",
    "    )\n",
    "    full_pipeline = Pipeline(\n",
    "        steps=[(\"preprocessor\", preprocessor), (\"model\", model)]\n",
    "    )\n",
    "    return full_pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "outliers removal function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def remove_outliers(series_with_mel_spec_list):\n",
    "    series_with_mel_spec_list = [e for l in series_with_mel_spec_list for e in l]\n",
    "\n",
    "    # print(\"before outliers: \", len(series_with_mel_spec_list))\n",
    "    i=0\n",
    "    for series_with_mel_spec in series_with_mel_spec_list:\n",
    "        if series_with_mel_spec[\"spectrogram\"] is None:\n",
    "            series_with_mel_spec_list.pop(i)\n",
    "        i+=1\n",
    "\n",
    "    # print(\"after outliers: \", len(series_with_mel_spec_list))\n",
    "\n",
    "    return series_with_mel_spec_list"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# model = RandomForestClassifier()\n",
    "# model = KNeighborsClassifier()\n",
    "model = SVC(cache_size=16000)\n",
    "\n",
    "model_name = type(model).__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if model_name == \"KNeighborsClassifier\":\n",
    "    best_par = {'model__n_jobs': -1, 'model__n_neighbors': 9, 'model__p': 1, 'model__weights': 'distance'} ; n_f_best, n_t_best = 8, 25\n",
    "elif model_name == \"SVC\":\n",
    "    best_par = {'model__C': 200, 'model__degree': 4, 'model__kernel': 'rbf', 'model__tol': 0.01} ; n_f_best, n_t_best = 8, 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using mel spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mel spec series list is done!\n",
      "before outliers:  19708\n",
      "after outliers:  9823\n"
     ]
    }
   ],
   "source": [
    "\n",
    "list_of_attributes = [\"path\", \"Id\", \"gender\", \"ageRange\", \"action\", \"object\"]\n",
    "series_with_mel_spec_list = mel_spectrogram_grid_search_PARALLEL(int_quale_silenzio=2, develop_eval_df=test_dev_df.copy(), list_of_attributes=list_of_attributes)\n",
    "\n",
    "series_with_mel_spec_list = remove_outliers(series_with_mel_spec_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "outlier removeas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import compute_sample_weight\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# FINAL SPECTRA\n",
    "# final_spectra_arr = characterize_spectrum(spectrum_list.copy(), n_time=n_t_best, n_freq=n_f_best)\n",
    "CHAR_SPEC_dataframe = characterize_spectrum_PARALLEL(series_with_mel_spec_list.copy(), n_time=n_t_best, n_freq=n_f_best)\n",
    "\n",
    "# rename columns\n",
    "CHAR_SPEC_dataframe = rename_columns_PARALLEL(CHAR_SPEC_dataframe)\n",
    "# num cat attributes\n",
    "numerical_attributes, categorical_attributes = num_cat_attributes(CHAR_SPEC_dataframe)\n",
    "# pipeline def\n",
    "full_pipeline = pipeline_definition(numerical_attributes, categorical_attributes, model)\n",
    "\n",
    "# pipeline def with best paramethers\n",
    "full_pipeline.set_params(**best_par)\n",
    "\n",
    "# print(final_spectra_arr.shape)\n",
    "\n",
    "y = CHAR_SPEC_dataframe['action'] + CHAR_SPEC_dataframe['object']\n",
    "columns_of_interest = numerical_attributes + categorical_attributes\n",
    "\n",
    "# sample_weight = compute_sample_weight(class_weight='balanced', y=y)\n",
    "\n",
    "# # training test split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(test_dev_df[columns_of_interest], y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counfusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(y_true,y_pred,label_names,clf_name):\n",
    "    \"\"\"\n",
    "    Draws a confusion matrix for the given y_pred and y_true values.\n",
    "     1. y_true = The actual classifications of the documents in the test dataset.\n",
    "     2. y_pred = The predicted classifications of the documents from the test dataset.\n",
    "     3. label_names = The actual names of the classes.\n",
    "    \"\"\"\n",
    "    # Calculate the confusion matrix using the expected and predicted values.\n",
    "    confusion_mat = confusion_matrix(y_true=np.array(y_true),y_pred=np.array(y_pred),labels=label_names)\n",
    "\n",
    "    #  Show the confusion matrix values.\n",
    "    fig = plt.figure(figsize=(12,12))\n",
    "    plt.imshow(confusion_mat, cmap=plt.cm.Blues, interpolation='nearest')\n",
    "\n",
    "    # Set the x, y and title labels for the plot.\n",
    "    plt.xlabel(\"Expected Outputes\", fontsize=10)\n",
    "    plt.ylabel(\"Actual Outputs\", fontsize=10)\n",
    "    plt.title(clf_name + \" Confusion Matrix\",fontsize=12)\n",
    "\n",
    "    # Arrange the label names on the x and y axis.\n",
    "    plt.xticks(np.arange(len(label_names)), label_names, rotation='horizontal')\n",
    "    plt.yticks(np.arange(len(label_names)), label_names)\n",
    "    plt.tick_params(axis='both', labelsize='10')\n",
    "    plt.tight_layout()\n",
    "    for (y, x), label in np.ndenumerate(confusion_mat):\n",
    "        if label != 0:\n",
    "            plt.text(x,y,label,ha='center',va='center', size='12')\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "CONFUSION_MATRIX = False\n",
    "if CONFUSION_MATRIX:\n",
    "    # Train Test Split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(CHAR_SPEC_dataframe[columns_of_interest], y, test_size=0.2, random_state=42)\n",
    "    # Fit pipeline\n",
    "    full_pipeline.fit(X_train, y_train)\n",
    "    # Predict pipeline\n",
    "    y_pred_test = full_pipeline.predict(X_test)\n",
    "    # confusion matric\n",
    "    labels = list(set(CHAR_SPEC_dataframe['action'] + CHAR_SPEC_dataframe['object']))\n",
    "    plot_confusion_matrix(y_test,y_pred_test,labels, \"meow\")\n",
    "\n",
    "    # Compute SCORE since we're already here\n",
    "    # print(f\"boh score is: {full_pipeline.score(X_test, y_test)}\")\n",
    "    print(\"ACCURACY score of model is: %.3f\" % accuracy_score(y_test, y_pred_test))\n",
    "\n",
    "    # RESET PIPELINE\n",
    "    full_pipeline = pipeline_definition(numerical_attributes, categorical_attributes, model)\n",
    "    # pipeline def with best paramethers\n",
    "    full_pipeline.set_params(**best_par);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# TRAIN DEL MODELLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_pipeline.fit(CHAR_SPEC_dataframe[columns_of_interest], y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "EVAL = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TEST SET\n",
    "if EVAL:\n",
    "    eval_df = pd.read_csv(\"dsl_data\\\\evaluation.csv\", header=0)\n",
    "id_eval = eval_df[\"Id\"]\n",
    "\n",
    "spectrum_list_eval = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# MEL OF TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mel spec series list is done!\n"
     ]
    }
   ],
   "source": [
    "list_of_attributes = [\"path\", \"Id\", \"gender\", \"ageRange\"]\n",
    "series_with_mel_spec_list_EVAL = mel_spectrogram_grid_search_PARALLEL(int_quale_silenzio=2, develop_eval_df=eval_df, list_of_attributes=list_of_attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "series_with_mel_spec_list_EVAL = [e for l in series_with_mel_spec_list_EVAL for e in l]\n",
    "i=0\n",
    "for series_with_mel_spec in series_with_mel_spec_list_EVAL:\n",
    "    if series_with_mel_spec[\"spectrogram\"] is None:\n",
    "        series_with_mel_spec_list_EVAL.pop(i)\n",
    "    i+=1\n",
    "i=0\n",
    "for series_with_mel_spec in series_with_mel_spec_list_EVAL:\n",
    "    if series_with_mel_spec[\"spectrogram\"] is None:\n",
    "        print(\"hi\")\n",
    "        series_with_mel_spec_list_EVAL.pop(i)\n",
    "    i+=1\n",
    "i=0\n",
    "for series_with_mel_spec in series_with_mel_spec_list_EVAL:\n",
    "    if series_with_mel_spec[\"spectrogram\"] is None:\n",
    "        print(\"hi\")\n",
    "        series_with_mel_spec_list_EVAL.pop(i)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# FINAL SPECTRA\n",
    "# final_spectra_arr = CHAR_SPEC_window_view(spectrum_list_eval, n_time=n_t_best, n_freq=n_f_best)\n",
    "# final_spectra_arr = characterize_spectrum(spectrum_list_eval.copy(), n_time=n_t_best, n_freq=n_f_best)\n",
    "\n",
    "\n",
    "CHAR_SPEC_dataframe_EVAL = characterize_spectrum_PARALLEL(series_with_mel_spec_list_EVAL.copy(), n_time=n_t_best, n_freq=n_f_best)\n",
    "# rename columns\n",
    "CHAR_SPEC_dataframe_EVAL = rename_columns_PARALLEL(CHAR_SPEC_dataframe_EVAL)\n",
    "# num cat attributes\n",
    "numerical_attributes, categorical_attributes = num_cat_attributes(CHAR_SPEC_dataframe_EVAL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "CHAR_SPEC_dataframe_EVAL = CHAR_SPEC_dataframe_EVAL[columns_of_interest]\n",
    "\n",
    "y_predict = full_pipeline.predict(CHAR_SPEC_dataframe_EVAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# PRINT TO FILE\n",
    "\n",
    "out_df = pd.DataFrame(data=y_predict, columns=[\"Predicted\"])\n",
    "out_df.index = id_eval\n",
    "out_df.index.name = \"Id\"\n",
    "# df['Id'] = df.index\n",
    "# print(out_df)\n",
    "out_df.to_csv(path_or_buf=\"dsl_data\\\\prediction.csv\", header=True, index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f073a0197ea64dc3cb4d3326148842498bf040a5de1a11b410340b35e42a8f60"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
